# Babelon ç¿»è­¯æœå‹™

## ğŸ“ é …ç›®æ¦‚è¿°

Babelon æ˜¯ä¸€å€‹åŸºæ–¼ FastAPI çš„å¤šèªè¨€éŸ³é »è½‰éŒ„èˆ‡ç¿»è­¯æœå‹™ï¼Œæ•´åˆäº†å…ˆé€²çš„ ASRï¼ˆè‡ªå‹•èªéŸ³è­˜åˆ¥ï¼‰å’Œ AI ç¿»è­¯æŠ€è¡“ã€‚è©²æœå‹™èƒ½å¤ å°‡éŸ³é »æ–‡ä»¶è½‰éŒ„ç‚ºæ–‡å­—ï¼Œä¸¦ç¿»è­¯æˆå¤šç¨®èªè¨€ï¼Œç‰¹åˆ¥é©ç”¨æ–¼æœƒè­°è¨˜éŒ„ã€å³æ™‚ç¿»è­¯ç­‰å ´æ™¯ã€‚

## âœ¨ ä¸»è¦åŠŸèƒ½

### ğŸ¯ æ ¸å¿ƒåŠŸèƒ½
- **éŸ³é »è½‰éŒ„**ï¼šæ”¯æ´å¤šç¨® Whisper æ¨¡å‹ï¼ˆlarge-v2, large-v3, turboï¼‰
- **å¤šèªè¨€ç¿»è­¯**ï¼šæ”¯æ´ä¸­æ–‡ï¼ˆç¹é«”ï¼‰ã€è‹±æ–‡ã€å¾·æ–‡ä¹‹é–“çš„äº’ç›¸ç¿»è­¯
- **å³æ™‚ä¸²æµ**ï¼šæ”¯æ´ Server-Sent Events (SSE) å³æ™‚ç¿»è­¯
- **å¤šé‡ç­–ç•¥è½‰éŒ„**ï¼šæœ€å¤š 4 ç¨®ç­–ç•¥æå‡è½‰éŒ„æº–ç¢ºåº¦
- **æ™ºèƒ½å¾Œè™•ç†**ï¼šè‡ªå‹•ä¿®æ­£ ASR å¸¸è¦‹éŒ¯èª¤

### ğŸ›  æŠ€è¡“ç‰¹è‰²
- **å¤šæ¨¡å‹æ”¯æ´**ï¼šæ•´åˆ OpenAI Whisperã€Gemmaã€Ollamaã€GPT-4o
- **GPU åŠ é€Ÿ**ï¼šæ”¯æ´ CUDA åŠ é€Ÿé‹ç®—
- **å®¹å™¨åŒ–éƒ¨ç½²**ï¼šDocker + Docker Compose å¿«é€Ÿéƒ¨ç½²
- **è³‡æºç®¡ç†**ï¼šè‡ªå‹•æ¸…ç†èˆŠéŸ³é »æ–‡ä»¶ï¼Œè¨˜æ†¶é«”å„ªåŒ–
- **éŒ¯èª¤é‡è©¦**ï¼šå¤šç­–ç•¥å®¹éŒ¯æ©Ÿåˆ¶

## ğŸ— ç³»çµ±æ¶æ§‹

```
Babelon/
â”œâ”€â”€ main.py                 # FastAPI ä¸»æ‡‰ç”¨ç¨‹å¼
â”œâ”€â”€ api/                    # API æ¨¡çµ„
â”‚   â”œâ”€â”€ model.py           # æ ¸å¿ƒæ¨¡å‹ç®¡ç†
â”‚   â”œâ”€â”€ gemma_translate.py # Gemma ç¿»è­¯å¼•æ“
â”‚   â”œâ”€â”€ gpt_translate.py   # GPT-4o ç¿»è­¯å¼•æ“
â”‚   â”œâ”€â”€ ollama_translate.py # Ollama ç¿»è­¯å¼•æ“
â”‚   â”œâ”€â”€ post_process.py    # å¾Œè™•ç†æ¨¡çµ„
â”‚   â””â”€â”€ threading_api.py   # å¤šåŸ·è¡Œç·’ API
â”œâ”€â”€ lib/                   # å…±ç”¨å‡½å¼åº«
â”‚   â”œâ”€â”€ base_object.py     # åŸºç¤ç‰©ä»¶å®šç¾©
â”‚   â”œâ”€â”€ constant.py        # å¸¸æ•¸èˆ‡è¨­å®š
â”‚   â””â”€â”€ azure_config.yaml  # Azure è¨­å®š
â”œâ”€â”€ tools/                 # å·¥å…·ç¨‹å¼
â”‚   â””â”€â”€ audio_splitter.py  # éŸ³é »åˆ†å‰²å·¥å…·
â”œâ”€â”€ audio/                 # éŸ³é »æª”æ¡ˆæš«å­˜
â”œâ”€â”€ logs/                  # æ—¥èªŒæª”æ¡ˆ
â””â”€â”€ old/                   # æ­·å²æª”æ¡ˆ
```

## ğŸš€ å¿«é€Ÿé–‹å§‹

### ç’°å¢ƒéœ€æ±‚
- Python 3.9+
- CUDA æ”¯æ´çš„ GPUï¼ˆå»ºè­°ï¼‰
- Docker & Docker Compose
- 4GB+ GPU è¨˜æ†¶é«”

### å®‰è£éƒ¨ç½²

#### æ–¹æ³•ä¸€ï¼šDocker éƒ¨ç½²ï¼ˆæ¨è–¦ï¼‰
```bash
# è¤‡è£½é …ç›®
git clone <repository-url>
cd Babelon

# å‰µå»ºç’°å¢ƒè®Šæ•¸æª”æ¡ˆ
cp .env.example .env
# ç·¨è¼¯ .env è¨­å®šæ‰€éœ€çš„ API é‡‘é‘°

# å•Ÿå‹•æœå‹™
docker-compose up -d

# é€²å…¥å®¹å™¨
docker exec -it babelon bash

# åœ¨å®¹å™¨å…§å•Ÿå‹•æœå‹™
python main.py
```

#### æ–¹æ³•äºŒï¼šæœ¬åœ°å®‰è£
```bash
# å®‰è£ä¾è³´
pip install -r requirements.txt

# è¨­å®šç’°å¢ƒè®Šæ•¸
export OPENAI_API_KEY="your-api-key"

# å•Ÿå‹•æœå‹™
python main.py
```

### åˆæ¬¡ä½¿ç”¨è¨­å®š

1. **Hugging Face ç™»å…¥**ï¼ˆä½¿ç”¨ Gemma æ¨¡å‹éœ€è¦ï¼‰
```bash
huggingface-cli login --token your_hf_token
```

2. **Ollama è¨­å®š**ï¼ˆå¯é¸ï¼‰
```bash
# å®‰è£ä¸¦å•Ÿå‹• Ollama
ollama pull gemma2:latest
ollama pull qwen2.5:latest
```

## ğŸ“‹ API æ–‡æª”

### åŸºæœ¬è³‡è¨Š
- **æœå‹™åœ°å€**ï¼š`http://localhost:80`
- **API æ–‡æª”**ï¼š`http://localhost:80/docs`
- **å¥åº·æª¢æŸ¥**ï¼š`GET /`

### ä¸»è¦ç«¯é»

#### 1. éŸ³é »è½‰éŒ„ç¿»è­¯
```http
POST /translate
Content-Type: multipart/form-data

file: audio file (.wav, .mp3, .m4a)
meeting_id: string
device_id: string  
audio_uid: string
times: datetime
o_lang: string (zh|en|de)
prev_text: string (å¯é¸ï¼Œå‰æ–‡èªå¢ƒ)
multi_strategy_transcription: int (1-4ï¼Œé è¨­1)
transcription_post_processing: bool (é è¨­true)
```

**å›æ‡‰æ ¼å¼**ï¼š
```json
{
  "status": "OK",
  "message": "ç¿»è­¯çµæœæ‘˜è¦",
  "data": {
    "meeting_id": "123",
    "device_id": "456", 
    "ori_lang": "zh",
    "text": {
      "zh": "ä¸­æ–‡ç¿»è­¯",
      "en": "English translation",
      "de": "Deutsche Ãœbersetzung"
    },
    "times": "2024-01-01T10:00:00",
    "audio_uid": "789",
    "transcribe_time": 2.5,
    "translate_time": 1.2
  }
}
```

#### 2. ç´”æ–‡å­—ç¿»è­¯
```http
POST /text_translate
Content-Type: application/x-www-form-urlencoded

text: è¦ç¿»è­¯çš„æ–‡å­—
language: ä¾†æºèªè¨€ (zh|en|de)
```

#### 3. å³æ™‚ä¸²æµç¿»è­¯ï¼ˆSSEï¼‰
```http
# ä¸Šå‚³éŸ³é »åˆ°ä½‡åˆ—
POST /sse_audio_translate

# é€£æ¥ä¸²æµ
GET /sse_audio_translate
Accept: text/event-stream

# åœæ­¢ä¸²æµ
POST /stop_sse
```

#### 4. æ¨¡å‹ç®¡ç†
```http
# æŸ¥çœ‹ç•¶å‰æ¨¡å‹
GET /get_current_model

# åˆ—å‡ºå¯ç”¨é¸é …
GET /list_optional_items

# æ›´æ›è½‰éŒ„æ¨¡å‹
POST /change_transcription_model
model_name: large_v2|large_v3|turbo

# æ›´æ›ç¿»è­¯æ–¹æ³•
POST /change_translation_method  
method_name: gemma4b|ollama-gemma|ollama-qwen|gpt4o

# è¨­å®šæç¤ºè©
POST /set_prompt
prompts: è‡ªå®šç¾©æç¤ºè©
```

## âš™ï¸ é…ç½®èªªæ˜

### æ”¯æ´çš„èªè¨€
- `zh`ï¼šç¹é«”ä¸­æ–‡ï¼ˆå°ç£ï¼‰
- `en`ï¼šè‹±æ–‡ï¼ˆç¾å¼ï¼‰
- `de`ï¼šå¾·æ–‡ï¼ˆæ¨™æº–å¾·èªï¼‰

### è½‰éŒ„æ¨¡å‹é¸é …
- `large_v2`ï¼šOpenAI Whisper Large v2ï¼ˆé è¨­ï¼‰
- `large_v3`ï¼šOpenAI Whisper Large v3
- `turbo`ï¼šOpenAI Whisper Large v3 Turbo
- `TCM`ï¼šè‡ªå®šç¾©æ¨¡å‹è·¯å¾‘

### ç¿»è­¯å¼•æ“é¸é …
- `gpt4o`ï¼šGPT-4oï¼ˆé è¨­ï¼Œéœ€è¦ OpenAI APIï¼‰
- `gemma4b`ï¼šGoogle Gemma 4Bï¼ˆæœ¬åœ°é‹è¡Œï¼‰
- `ollama-gemma`ï¼šOllama Gemma æ¨¡å‹
- `ollama-qwen`ï¼šOllama Qwen æ¨¡å‹

### ç’°å¢ƒè®Šæ•¸è¨­å®š
```bash
# OpenAI APIï¼ˆGPT-4o ç¿»è­¯ï¼‰
OPENAI_API_KEY=your_openai_api_key

# Azure OpenAIï¼ˆå¯é¸ï¼‰
AZURE_OPENAI_ENDPOINT=your_endpoint
AZURE_OPENAI_API_KEY=your_azure_key

# GPU è¨­å®š
NVIDIA_VISIBLE_DEVICES=all
CUDA_VISIBLE_DEVICES=0
```

## ğŸ”§ é€²éšåŠŸèƒ½

### å¤šé‡ç­–ç•¥è½‰éŒ„
ç³»çµ±æ”¯æ´æœ€å¤š 4 ç¨®è½‰éŒ„ç­–ç•¥ä»¥æå‡æº–ç¢ºåº¦ï¼š
1. **ç­–ç•¥ 1**ï¼šä½¿ç”¨è‡ªå®šç¾©æç¤ºè© + å‰æ–‡èªå¢ƒ
2. **ç­–ç•¥ 2**ï¼šåƒ…ä½¿ç”¨è‡ªå®šç¾©æç¤ºè©
3. **ç­–ç•¥ 3**ï¼šç„¡æç¤ºè©ï¼Œä½æº«åº¦æ¡æ¨£
4. **ç­–ç•¥ 4**ï¼šé«˜æº«åº¦å¤šæ¨£åŒ–æ¡æ¨£

### æ™ºèƒ½å¾Œè™•ç†
- è‡ªå‹•ä¿®æ­£ ASR å¸¸è¦‹éŒ¯èª¤
- å“ç‰Œåç¨±æ¨™æº–åŒ–
- èªæ³•éŒ¯èª¤ä¿®æ­£
- å¹»è¦ºæª¢æ¸¬èˆ‡éæ¿¾

### è‡ªå‹•è³‡æºç®¡ç†
- å®šæ™‚æ¸…ç† 24 å°æ™‚å‰çš„éŸ³é »æª”æ¡ˆ
- GPU è¨˜æ†¶é«”è‡ªå‹•å›æ”¶
- æ¨¡å‹ç†±åˆ‡æ›ä¸ä¸­æ–·æœå‹™

## ğŸ¯ ä½¿ç”¨ç¯„ä¾‹

### Python å®¢æˆ¶ç«¯ç¯„ä¾‹
```python
import requests

# éŸ³é »ç¿»è­¯
files = {'file': open('audio.wav', 'rb')}
data = {
    'meeting_id': '001',
    'device_id': 'mic_01', 
    'audio_uid': 'audio_001',
    'times': '2024-01-01T10:00:00',
    'o_lang': 'zh',
    'multi_strategy_transcription': 2
}

response = requests.post(
    'http://localhost:80/translate',
    files=files,
    data=data
)
print(response.json())

# æ–‡å­—ç¿»è­¯
data = {'text': 'ä½ å¥½ä¸–ç•Œ', 'language': 'zh'}
response = requests.post(
    'http://localhost:80/text_translate',
    data=data
)
print(response.json())
```

### curl ç¯„ä¾‹
```bash
# éŸ³é »ç¿»è­¯
curl -X POST "http://localhost:80/translate" \
  -F "file=@audio.wav" \
  -F "meeting_id=001" \
  -F "device_id=mic_01" \
  -F "audio_uid=audio_001" \
  -F "times=2024-01-01T10:00:00" \
  -F "o_lang=zh"

# æ–‡å­—ç¿»è­¯  
curl -X POST "http://localhost:80/text_translate" \
  -F "text=Hello World" \
  -F "language=en"
```

## ğŸ“Š æ•ˆèƒ½æœ€ä½³åŒ–

### å»ºè­°çš„ç¡¬é«”é…ç½®
- **GPU**ï¼šNVIDIA RTX 3080 ä»¥ä¸Š
- **è¨˜æ†¶é«”**ï¼š16GB+ RAM
- **å„²å­˜**ï¼šSSD æ¨è–¦
- **ç¶²è·¯**ï¼šç©©å®šçš„ç¶²è·¯é€£ç·šï¼ˆAPI èª¿ç”¨ï¼‰

### æ•ˆèƒ½èª¿æ ¡
```python
# åœ¨ constant.py ä¸­èª¿æ•´åƒæ•¸
WAITING_TIME = 60           # è½‰éŒ„è¶…æ™‚æ™‚é–“
MAX_NUM_STRATEGIES = 4      # æœ€å¤§ç­–ç•¥æ•¸
SILENCE_PADDING = True      # éœéŸ³å¡«å……
RTF = True                  # è¨ˆç®—å³æ™‚ä¿‚æ•¸
```

## ğŸ›¡ï¸ å®‰å…¨æ€§è€ƒæ…®

### API å®‰å…¨
- å»ºè­°ä½¿ç”¨åå‘ä»£ç†ï¼ˆnginxï¼‰
- è¨­å®š API é€Ÿç‡é™åˆ¶
- ç”Ÿç”¢ç’°å¢ƒå•Ÿç”¨ HTTPS

### è³‡æ–™éš±ç§
- éŸ³é »æª”æ¡ˆè‡ªå‹•æ¸…ç†
- æ•æ„Ÿè³‡è¨Šæ—¥èªŒé®è”½
- æ”¯æ´æœ¬åœ°éƒ¨ç½²ï¼Œè³‡æ–™ä¸å‡ºå¢ƒ

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

#### 1. GPU è¨˜æ†¶é«”ä¸è¶³
```bash
# æª¢æŸ¥ GPU ä½¿ç”¨ç‹€æ³
nvidia-smi

# é™ä½æ¨¡å‹è¦æ¨¡
# æ”¹ç”¨ turbo æ¨¡å‹æ›¿ä»£ large_v3
```

#### 2. æ¨¡å‹è¼‰å…¥å¤±æ•—
```bash
# æª¢æŸ¥ Hugging Face ç™»å…¥ç‹€æ…‹
huggingface-cli whoami

# æ¸…é™¤æ¨¡å‹å¿«å–
rm -rf ~/.cache/huggingface/
```

#### 3. ç¿»è­¯ API éŒ¯èª¤
```bash
# æª¢æŸ¥ API é‡‘é‘°è¨­å®š
echo $OPENAI_API_KEY

# æŸ¥çœ‹è©³ç´°éŒ¯èª¤æ—¥èªŒ
tail -f logs/app.log
```

### æ—¥èªŒé™¤éŒ¯
```bash
# æŸ¥çœ‹å³æ™‚æ—¥èªŒ
tail -f logs/app.log

# æœå°‹ç‰¹å®šéŒ¯èª¤
grep "error" logs/app.log

# èª¿æ•´æ—¥èªŒç­‰ç´šï¼ˆåœ¨ main.py ä¸­ï¼‰
logging.basicConfig(level=logging.DEBUG)
```

## ğŸ¤ è²¢ç»æŒ‡å—

### é–‹ç™¼ç’°å¢ƒè¨­å®š
```bash
git clone <repository-url>
cd Babelon
pip install -r requirements.txt
pre-commit install
```

### ç¨‹å¼ç¢¼è¦ç¯„
- ä½¿ç”¨ Black æ ¼å¼åŒ–ç¨‹å¼ç¢¼
- éµå¾ª PEP 8 æ¨™æº–
- æ·»åŠ é©ç•¶çš„å‹åˆ¥æç¤º
- æ’°å¯«æ¸¬è©¦æ¡ˆä¾‹

## ğŸ“„ æˆæ¬Šæ¢æ¬¾

æœ¬é …ç›®æ¡ç”¨ [MIT License](LICENSE)

## ğŸ“ è¯çµ¡è³‡è¨Š

- **é …ç›®ç¶­è­·è€…**ï¼š[æ‚¨çš„åç¨±]
- **å•é¡Œå›å ±**ï¼š[GitHub Issues]
- **æŠ€è¡“è¨è«–**ï¼š[è¨è«–å€é€£çµ]

## ğŸ”„ æ›´æ–°æ—¥èªŒ

### v1.0.0 (2024-01-01)
- åˆå§‹ç‰ˆæœ¬ç™¼å¸ƒ
- æ”¯æ´å¤šèªè¨€éŸ³é »è½‰éŒ„ç¿»è­¯
- æ•´åˆå¤šç¨® AI æ¨¡å‹
- å¯¦ç¾ SSE å³æ™‚ä¸²æµ

---

**æ³¨æ„**ï¼šæœ¬æœå‹™ä»åœ¨æŒçºŒé–‹ç™¼ä¸­ï¼Œéƒ¨åˆ†åŠŸèƒ½å¯èƒ½æœƒæœ‰èª¿æ•´ã€‚ç”Ÿç”¢ç’°å¢ƒä½¿ç”¨å‰è«‹å……åˆ†æ¸¬è©¦ã€‚